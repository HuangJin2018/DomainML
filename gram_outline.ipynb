{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9ac58ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import tensorflow as tf\n",
    "import mlflow\n",
    "import random\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "sys.argv.clear()\n",
    "sys.argv.append(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f941b579",
   "metadata": {},
   "source": [
    "## Experiment and mlflow configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e11737e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import config\n",
    "from src.features import preprocessing,sequences,knowledge\n",
    "from src.training import models\n",
    "from src import refinement\n",
    "\n",
    "experiment_config = config.ExperimentConfig()\n",
    "experiment_config.model_type = \"gram\"\n",
    "\n",
    "model_config = models.config.ModelConfig()\n",
    "model_config.rnn_type: str = \"gru\"\n",
    "\n",
    "# keep all other default configurations \n",
    "mimic_preprocessor_config = preprocessing.mimic.MimicPreprocessorConfig()\n",
    "sequence_config = sequences.config.SequenceConfig()\n",
    "knowledge_config = knowledge.config.KnowledgeConfig()\n",
    "refinement_config = refinement.config.RefinementConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "befb4e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_all_configs_to_mlflow():\n",
    "    for config in [\n",
    "        experiment_config,\n",
    "        mimic_preprocessor_config,\n",
    "        sequence_config,\n",
    "        model_config,\n",
    "        knowledge_config,\n",
    "        refinement_config,\n",
    "    ]:\n",
    "        for config_name, config_value in vars(config).items():\n",
    "            full_config_name = config.__class__.__name__ + config_name\n",
    "            mlflow.log_param(full_config_name, str(config_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0f13078",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Domain Guided Monitoring\")\n",
    "with mlflow.start_run() as run:\n",
    "    run_id = run.info.run_id\n",
    "logging.info(\"Starting run %s\", run_id)\n",
    "tf.random.set_seed(experiment_config.tensorflow_seed)\n",
    "random.seed(experiment_config.random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deebc46b",
   "metadata": {},
   "source": [
    "## Load MIMIC sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de07d435",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_preprocessor = preprocessing.MimicPreprocessor(\n",
    "    config=mimic_preprocessor_config,\n",
    ")\n",
    "sequence_column_name = mimic_preprocessor_config.sequence_column_name\n",
    "sequence_df = sequence_preprocessor.load_data()\n",
    "\n",
    "transformer = sequences.transformer.NextPartialSequenceTransformerFromDataframe(sequence_config)\n",
    "metadata = transformer.collect_metadata(sequence_df, sequence_column_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aa2c1f",
   "metadata": {},
   "source": [
    "## Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7f899c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_df_pkl_file: str = \"data/sequences_df.pkl\"\n",
    "sequence_df.to_pickle(sequence_df_pkl_file)\n",
    "\n",
    "train_sequences, test_sequences = transformer._split_train_test(sequence_df, sequence_column_name)\n",
    "\n",
    "def generate(for_train):\n",
    "    relevant_sequences = train_sequences if for_train else test_sequences\n",
    "    for sequence in relevant_sequences:\n",
    "        split_sequences = transformer._split_sequence(sequence)\n",
    "        for split_sequence in split_sequences:\n",
    "            transformer._translate_and_pad(split_sequence, metadata)\n",
    "            yield split_sequence.x_vecs_stacked, split_sequence.y_vec\n",
    "\n",
    "def generate_train():\n",
    "    return generate(for_train=True)\n",
    "\n",
    "def generate_test():\n",
    "    return generate(for_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2049c0f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 00:54:53.820510: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-02 00:54:53.820572: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-02 00:54:53.820628: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (hj-ubuntu): /proc/driver/nvidia/version does not exist\n",
      "2022-05-02 00:54:53.823678: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-05-02 00:54:53.855411: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2599990000 Hz\n",
      "2022-05-02 00:54:53.857172: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7efbd0000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-05-02 00:54:53.857227: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    }
   ],
   "source": [
    "train_dataset = (\n",
    "    tf.data.Dataset.from_generator(\n",
    "        generate_train,\n",
    "        output_types=(tf.float32, tf.float32),\n",
    "    )\n",
    "    .shuffle(\n",
    "        experiment_config.dataset_shuffle_buffer,\n",
    "        seed=experiment_config.dataset_shuffle_seed,\n",
    "        reshuffle_each_iteration=True,\n",
    "    )\n",
    "    .batch(experiment_config.batch_size)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset.from_generator(\n",
    "        generate_test,\n",
    "        output_types=(tf.float32, tf.float32),\n",
    "    )\n",
    "    .batch(experiment_config.batch_size)\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfbc6d6",
   "metadata": {},
   "source": [
    "## Process knowledge and genarate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b714bde6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building Hierarchy from df: 18960it [00:01, 17908.69it/s]\n",
      "Initializing gram_embedding connections: 100%|â–ˆ| 939/939 [00:04<00:00, 203.44it/\n"
     ]
    }
   ],
   "source": [
    "# process knowledge to generate hierarchy\n",
    "hierarchy_preprocessor = preprocessing.ICD9HierarchyPreprocessor(\n",
    "    config=mimic_preprocessor_config\n",
    ")\n",
    "hierarchy_df = hierarchy_preprocessor.load_data()\n",
    "hierarchy = knowledge.HierarchyKnowledge(\n",
    "    config=knowledge_config,\n",
    ")\n",
    "hierarchy.build_hierarchy_from_df(hierarchy_df, metadata.x_vocab)\n",
    "\n",
    "# load model\n",
    "model = models.GramModel()\n",
    "\n",
    "# build model\n",
    "model.build(metadata, hierarchy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb1fbb0",
   "metadata": {},
   "source": [
    "## Run Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "74d03a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating percentile frequencies...: 351it [00:04, 84.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 00:55:39.811920: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:906] Skipping loop optimization for Merge node with control input: sequential/gram_embedding/Assert_5/AssertGuard/branch_executed/_29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    350/Unknown - 5s 16ms/step - loss: 0.0807 - categorical_accuracy: 0.0962 - top_5_categorical_accuracy: 0.3244 - top_10_categorical_accuracy: 0.4353 - top_20_categorical_accuracy: 0.4971 - top_5_categorical_accuracy_cp0: 0.2948 - top_5_categorical_accuracy_cp1: 0.3294 - top_5_categorical_accuracy_cp2: 0.3421 - top_5_categorical_accuracy_cp3: 0.3750 - top_5_categorical_accuracy_cp4: 0.4155 - top_5_categorical_accuracy_p0: 0.2766 - top_5_categorical_accuracy_p1: 0.2412 - top_5_categorical_accuracy_p2: 0.2666 - top_5_categorical_accuracy_p3: 0.2922 - top_5_categorical_accuracy_p4: 0.3580 - top_10_categorical_accuracy_cp0: 0.3933 - top_10_categorical_accuracy_cp1: 0.4394 - top_10_categorical_accuracy_cp2: 0.4527 - top_10_categorical_accuracy_cp3: 0.4989 - top_10_categorical_accuracy_cp4: 0.5466 - top_10_categorical_accuracy_p0: 0.2766 - top_10_categorical_accuracy_p1: 0.3306 - top_10_categorical_accuracy_p2: 0.3355 - top_10_categorical_accuracy_p3: 0.3854 - top_10_categorical_accuracy_p4: 0.4754 - top_20_categorical_accuracy_cp0: 0.4409 - top_20_categorical_accuracy_cp1: 0.4921 - top_20_categorical_accuracy_cp2: 0.5073 - top_20_categorical_accuracy_cp3: 0.5659 - top_20_categorical_accuracy_cp4: 0.6097 - top_20_categorical_accuracy_p0: 0.3404 - top_20_categorical_accuracy_p1: 0.3597 - top_20_categorical_accuracy_p2: 0.3768 - top_20_categorical_accuracy_p3: 0.4307 - top_20_categorical_accuracy_p4: 0.5336"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 00:55:52.170477: W tensorflow/core/grappler/optimizers/loop_optimizer.cc:906] Skipping loop optimization for Merge node with control input: sequential/gram_embedding/Assert_5/AssertGuard/branch_executed/_29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/351 [==============================] - 12s 35ms/step - loss: 0.0807 - categorical_accuracy: 0.0962 - top_5_categorical_accuracy: 0.3241 - top_10_categorical_accuracy: 0.4351 - top_20_categorical_accuracy: 0.4969 - top_5_categorical_accuracy_cp0: 0.2946 - top_5_categorical_accuracy_cp1: 0.3293 - top_5_categorical_accuracy_cp2: 0.3420 - top_5_categorical_accuracy_cp3: 0.3748 - top_5_categorical_accuracy_cp4: 0.4153 - top_5_categorical_accuracy_p0: 0.2766 - top_5_categorical_accuracy_p1: 0.2412 - top_5_categorical_accuracy_p2: 0.2663 - top_5_categorical_accuracy_p3: 0.2919 - top_5_categorical_accuracy_p4: 0.3578 - top_10_categorical_accuracy_cp0: 0.3932 - top_10_categorical_accuracy_cp1: 0.4394 - top_10_categorical_accuracy_cp2: 0.4527 - top_10_categorical_accuracy_cp3: 0.4988 - top_10_categorical_accuracy_cp4: 0.5465 - top_10_categorical_accuracy_p0: 0.2766 - top_10_categorical_accuracy_p1: 0.3306 - top_10_categorical_accuracy_p2: 0.3356 - top_10_categorical_accuracy_p3: 0.3851 - top_10_categorical_accuracy_p4: 0.4753 - top_20_categorical_accuracy_cp0: 0.4407 - top_20_categorical_accuracy_cp1: 0.4921 - top_20_categorical_accuracy_cp2: 0.5073 - top_20_categorical_accuracy_cp3: 0.5658 - top_20_categorical_accuracy_cp4: 0.6096 - top_20_categorical_accuracy_p0: 0.3404 - top_20_categorical_accuracy_p1: 0.3597 - top_20_categorical_accuracy_p2: 0.3769 - top_20_categorical_accuracy_p3: 0.4303 - top_20_categorical_accuracy_p4: 0.5336 - val_loss: 0.0736 - val_categorical_accuracy: 0.3114 - val_top_5_categorical_accuracy: 0.4338 - val_top_10_categorical_accuracy: 0.4913 - val_top_20_categorical_accuracy: 0.5137 - val_top_5_categorical_accuracy_cp0: 0.3653 - val_top_5_categorical_accuracy_cp1: 0.4362 - val_top_5_categorical_accuracy_cp2: 0.4581 - val_top_5_categorical_accuracy_cp3: 0.5026 - val_top_5_categorical_accuracy_cp4: 0.5753 - val_top_5_categorical_accuracy_p0: 0.4167 - val_top_5_categorical_accuracy_p1: 0.3729 - val_top_5_categorical_accuracy_p2: 0.3122 - val_top_5_categorical_accuracy_p3: 0.3549 - val_top_5_categorical_accuracy_p4: 0.4780 - val_top_10_categorical_accuracy_cp0: 0.4179 - val_top_10_categorical_accuracy_cp1: 0.4914 - val_top_10_categorical_accuracy_cp2: 0.5091 - val_top_10_categorical_accuracy_cp3: 0.5829 - val_top_10_categorical_accuracy_cp4: 0.6257 - val_top_10_categorical_accuracy_p0: 0.5000 - val_top_10_categorical_accuracy_p1: 0.4068 - val_top_10_categorical_accuracy_p2: 0.3460 - val_top_10_categorical_accuracy_p3: 0.4131 - val_top_10_categorical_accuracy_p4: 0.5360 - val_top_20_categorical_accuracy_cp0: 0.4331 - val_top_20_categorical_accuracy_cp1: 0.5044 - val_top_20_categorical_accuracy_cp2: 0.5270 - val_top_20_categorical_accuracy_cp3: 0.6106 - val_top_20_categorical_accuracy_cp4: 0.6362 - val_top_20_categorical_accuracy_p0: 0.5000 - val_top_20_categorical_accuracy_p1: 0.4068 - val_top_20_categorical_accuracy_p2: 0.3502 - val_top_20_categorical_accuracy_p3: 0.4249 - val_top_20_categorical_accuracy_p4: 0.5534\n",
      "Epoch 2/10\n",
      "351/351 [==============================] - 6s 18ms/step - loss: 0.0763 - categorical_accuracy: 0.1426 - top_5_categorical_accuracy: 0.4074 - top_10_categorical_accuracy: 0.4895 - top_20_categorical_accuracy: 0.5209 - top_5_categorical_accuracy_cp0: 0.3691 - top_5_categorical_accuracy_cp1: 0.4169 - top_5_categorical_accuracy_cp2: 0.4374 - top_5_categorical_accuracy_cp3: 0.4769 - top_5_categorical_accuracy_cp4: 0.5312 - top_5_categorical_accuracy_p0: 0.2553 - top_5_categorical_accuracy_p1: 0.2807 - top_5_categorical_accuracy_p2: 0.3130 - top_5_categorical_accuracy_p3: 0.3613 - top_5_categorical_accuracy_p4: 0.4559 - top_10_categorical_accuracy_cp0: 0.4359 - top_10_categorical_accuracy_cp1: 0.4935 - top_10_categorical_accuracy_cp2: 0.5089 - top_10_categorical_accuracy_cp3: 0.5655 - top_10_categorical_accuracy_cp4: 0.6175 - top_10_categorical_accuracy_p0: 0.3404 - top_10_categorical_accuracy_p1: 0.3368 - top_10_categorical_accuracy_p2: 0.3661 - top_10_categorical_accuracy_p3: 0.4234 - top_10_categorical_accuracy_p4: 0.5356 - top_20_categorical_accuracy_cp0: 0.4591 - top_20_categorical_accuracy_cp1: 0.5152 - top_20_categorical_accuracy_cp2: 0.5303 - top_20_categorical_accuracy_cp3: 0.5964 - top_20_categorical_accuracy_cp4: 0.6397 - top_20_categorical_accuracy_p0: 0.3617 - top_20_categorical_accuracy_p1: 0.3638 - top_20_categorical_accuracy_p2: 0.3897 - top_20_categorical_accuracy_p3: 0.4442 - top_20_categorical_accuracy_p4: 0.5598 - val_loss: 0.0734 - val_categorical_accuracy: 0.3114 - val_top_5_categorical_accuracy: 0.4338 - val_top_10_categorical_accuracy: 0.5004 - val_top_20_categorical_accuracy: 0.5054 - val_top_5_categorical_accuracy_cp0: 0.3653 - val_top_5_categorical_accuracy_cp1: 0.4362 - val_top_5_categorical_accuracy_cp2: 0.4581 - val_top_5_categorical_accuracy_cp3: 0.5026 - val_top_5_categorical_accuracy_cp4: 0.5753 - val_top_5_categorical_accuracy_p0: 0.4167 - val_top_5_categorical_accuracy_p1: 0.3729 - val_top_5_categorical_accuracy_p2: 0.3122 - val_top_5_categorical_accuracy_p3: 0.3549 - val_top_5_categorical_accuracy_p4: 0.4780 - val_top_10_categorical_accuracy_cp0: 0.4243 - val_top_10_categorical_accuracy_cp1: 0.4974 - val_top_10_categorical_accuracy_cp2: 0.5159 - val_top_10_categorical_accuracy_cp3: 0.5991 - val_top_10_categorical_accuracy_cp4: 0.6337 - val_top_10_categorical_accuracy_p0: 0.5000 - val_top_10_categorical_accuracy_p1: 0.4068 - val_top_10_categorical_accuracy_p2: 0.3460 - val_top_10_categorical_accuracy_p3: 0.4186 - val_top_10_categorical_accuracy_p4: 0.5451 - val_top_20_categorical_accuracy_cp0: 0.4271 - val_top_20_categorical_accuracy_cp1: 0.4992 - val_top_20_categorical_accuracy_cp2: 0.5182 - val_top_20_categorical_accuracy_cp3: 0.6054 - val_top_20_categorical_accuracy_cp4: 0.6350 - val_top_20_categorical_accuracy_p0: 0.5000 - val_top_20_categorical_accuracy_p1: 0.4068 - val_top_20_categorical_accuracy_p2: 0.3502 - val_top_20_categorical_accuracy_p3: 0.4195 - val_top_20_categorical_accuracy_p4: 0.5480\n",
      "Epoch 3/10\n",
      "351/351 [==============================] - 6s 18ms/step - loss: 0.0761 - categorical_accuracy: 0.1505 - top_5_categorical_accuracy: 0.4232 - top_10_categorical_accuracy: 0.4900 - top_20_categorical_accuracy: 0.5206 - top_5_categorical_accuracy_cp0: 0.3828 - top_5_categorical_accuracy_cp1: 0.4313 - top_5_categorical_accuracy_cp2: 0.4543 - top_5_categorical_accuracy_cp3: 0.4933 - top_5_categorical_accuracy_cp4: 0.5518 - top_5_categorical_accuracy_p0: 0.2340 - top_5_categorical_accuracy_p1: 0.2911 - top_5_categorical_accuracy_p2: 0.3258 - top_5_categorical_accuracy_p3: 0.3782 - top_5_categorical_accuracy_p4: 0.4724 - top_10_categorical_accuracy_cp0: 0.4369 - top_10_categorical_accuracy_cp1: 0.4947 - top_10_categorical_accuracy_cp2: 0.5084 - top_10_categorical_accuracy_cp3: 0.5632 - top_10_categorical_accuracy_cp4: 0.6190 - top_10_categorical_accuracy_p0: 0.3617 - top_10_categorical_accuracy_p1: 0.3389 - top_10_categorical_accuracy_p2: 0.3656 - top_10_categorical_accuracy_p3: 0.4252 - top_10_categorical_accuracy_p4: 0.5357 - top_20_categorical_accuracy_cp0: 0.4581 - top_20_categorical_accuracy_cp1: 0.5150 - top_20_categorical_accuracy_cp2: 0.5301 - top_20_categorical_accuracy_cp3: 0.5958 - top_20_categorical_accuracy_cp4: 0.6391 - top_20_categorical_accuracy_p0: 0.3617 - top_20_categorical_accuracy_p1: 0.3638 - top_20_categorical_accuracy_p2: 0.3892 - top_20_categorical_accuracy_p3: 0.4434 - top_20_categorical_accuracy_p4: 0.5593 - val_loss: 0.0734 - val_categorical_accuracy: 0.3114 - val_top_5_categorical_accuracy: 0.4338 - val_top_10_categorical_accuracy: 0.5004 - val_top_20_categorical_accuracy: 0.5146 - val_top_5_categorical_accuracy_cp0: 0.3653 - val_top_5_categorical_accuracy_cp1: 0.4362 - val_top_5_categorical_accuracy_cp2: 0.4581 - val_top_5_categorical_accuracy_cp3: 0.5026 - val_top_5_categorical_accuracy_cp4: 0.5753 - val_top_5_categorical_accuracy_p0: 0.4167 - val_top_5_categorical_accuracy_p1: 0.3729 - val_top_5_categorical_accuracy_p2: 0.3122 - val_top_5_categorical_accuracy_p3: 0.3549 - val_top_5_categorical_accuracy_p4: 0.4780 - val_top_10_categorical_accuracy_cp0: 0.4243 - val_top_10_categorical_accuracy_cp1: 0.4974 - val_top_10_categorical_accuracy_cp2: 0.5159 - val_top_10_categorical_accuracy_cp3: 0.5991 - val_top_10_categorical_accuracy_cp4: 0.6337 - val_top_10_categorical_accuracy_p0: 0.5000 - val_top_10_categorical_accuracy_p1: 0.4068 - val_top_10_categorical_accuracy_p2: 0.3460 - val_top_10_categorical_accuracy_p3: 0.4186 - val_top_10_categorical_accuracy_p4: 0.5451 - val_top_20_categorical_accuracy_cp0: 0.4340 - val_top_20_categorical_accuracy_cp1: 0.5050 - val_top_20_categorical_accuracy_cp2: 0.5283 - val_top_20_categorical_accuracy_cp3: 0.6116 - val_top_20_categorical_accuracy_cp4: 0.6362 - val_top_20_categorical_accuracy_p0: 0.5000 - val_top_20_categorical_accuracy_p1: 0.4068 - val_top_20_categorical_accuracy_p2: 0.3502 - val_top_20_categorical_accuracy_p3: 0.4258 - val_top_20_categorical_accuracy_p4: 0.5542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "351/351 [==============================] - 6s 17ms/step - loss: 0.0761 - categorical_accuracy: 0.1462 - top_5_categorical_accuracy: 0.4272 - top_10_categorical_accuracy: 0.4921 - top_20_categorical_accuracy: 0.5221 - top_5_categorical_accuracy_cp0: 0.3873 - top_5_categorical_accuracy_cp1: 0.4362 - top_5_categorical_accuracy_cp2: 0.4577 - top_5_categorical_accuracy_cp3: 0.5008 - top_5_categorical_accuracy_cp4: 0.5569 - top_5_categorical_accuracy_p0: 0.2340 - top_5_categorical_accuracy_p1: 0.2723 - top_5_categorical_accuracy_p2: 0.3287 - top_5_categorical_accuracy_p3: 0.3796 - top_5_categorical_accuracy_p4: 0.4779 - top_10_categorical_accuracy_cp0: 0.4397 - top_10_categorical_accuracy_cp1: 0.4975 - top_10_categorical_accuracy_cp2: 0.5113 - top_10_categorical_accuracy_cp3: 0.5671 - top_10_categorical_accuracy_cp4: 0.6217 - top_10_categorical_accuracy_p0: 0.3617 - top_10_categorical_accuracy_p1: 0.3326 - top_10_categorical_accuracy_p2: 0.3705 - top_10_categorical_accuracy_p3: 0.4268 - top_10_categorical_accuracy_p4: 0.5388 - top_20_categorical_accuracy_cp0: 0.4586 - top_20_categorical_accuracy_cp1: 0.5146 - top_20_categorical_accuracy_cp2: 0.5297 - top_20_categorical_accuracy_cp3: 0.5961 - top_20_categorical_accuracy_cp4: 0.6394 - top_20_categorical_accuracy_p0: 0.3617 - top_20_categorical_accuracy_p1: 0.3617 - top_20_categorical_accuracy_p2: 0.3902 - top_20_categorical_accuracy_p3: 0.4434 - top_20_categorical_accuracy_p4: 0.5593 - val_loss: 0.0733 - val_categorical_accuracy: 0.3122 - val_top_5_categorical_accuracy: 0.4363 - val_top_10_categorical_accuracy: 0.5037 - val_top_20_categorical_accuracy: 0.5212 - val_top_5_categorical_accuracy_cp0: 0.3663 - val_top_5_categorical_accuracy_cp1: 0.4362 - val_top_5_categorical_accuracy_cp2: 0.4581 - val_top_5_categorical_accuracy_cp3: 0.5026 - val_top_5_categorical_accuracy_cp4: 0.5753 - val_top_5_categorical_accuracy_p0: 0.4167 - val_top_5_categorical_accuracy_p1: 0.3729 - val_top_5_categorical_accuracy_p2: 0.3122 - val_top_5_categorical_accuracy_p3: 0.3549 - val_top_5_categorical_accuracy_p4: 0.4782 - val_top_10_categorical_accuracy_cp0: 0.4255 - val_top_10_categorical_accuracy_cp1: 0.4974 - val_top_10_categorical_accuracy_cp2: 0.5159 - val_top_10_categorical_accuracy_cp3: 0.5991 - val_top_10_categorical_accuracy_cp4: 0.6337 - val_top_10_categorical_accuracy_p0: 0.5000 - val_top_10_categorical_accuracy_p1: 0.4068 - val_top_10_categorical_accuracy_p2: 0.3460 - val_top_10_categorical_accuracy_p3: 0.4186 - val_top_10_categorical_accuracy_p4: 0.5454 - val_top_20_categorical_accuracy_cp0: 0.4356 - val_top_20_categorical_accuracy_cp1: 0.5038 - val_top_20_categorical_accuracy_cp2: 0.5260 - val_top_20_categorical_accuracy_cp3: 0.6090 - val_top_20_categorical_accuracy_cp4: 0.6362 - val_top_20_categorical_accuracy_p0: 0.5000 - val_top_20_categorical_accuracy_p1: 0.4068 - val_top_20_categorical_accuracy_p2: 0.3502 - val_top_20_categorical_accuracy_p3: 0.4249 - val_top_20_categorical_accuracy_p4: 0.5533\n",
      "Epoch 5/10\n",
      "351/351 [==============================] - 6s 18ms/step - loss: 0.0760 - categorical_accuracy: 0.1633 - top_5_categorical_accuracy: 0.4305 - top_10_categorical_accuracy: 0.4983 - top_20_categorical_accuracy: 0.5264 - top_5_categorical_accuracy_cp0: 0.3875 - top_5_categorical_accuracy_cp1: 0.4340 - top_5_categorical_accuracy_cp2: 0.4588 - top_5_categorical_accuracy_cp3: 0.4995 - top_5_categorical_accuracy_cp4: 0.5566 - top_5_categorical_accuracy_p0: 0.2128 - top_5_categorical_accuracy_p1: 0.2973 - top_5_categorical_accuracy_p2: 0.3317 - top_5_categorical_accuracy_p3: 0.3808 - top_5_categorical_accuracy_p4: 0.4771 - top_10_categorical_accuracy_cp0: 0.4422 - top_10_categorical_accuracy_cp1: 0.4990 - top_10_categorical_accuracy_cp2: 0.5124 - top_10_categorical_accuracy_cp3: 0.5703 - top_10_categorical_accuracy_cp4: 0.6235 - top_10_categorical_accuracy_p0: 0.3617 - top_10_categorical_accuracy_p1: 0.3410 - top_10_categorical_accuracy_p2: 0.3690 - top_10_categorical_accuracy_p3: 0.4281 - top_10_categorical_accuracy_p4: 0.5410 - top_20_categorical_accuracy_cp0: 0.4606 - top_20_categorical_accuracy_cp1: 0.5148 - top_20_categorical_accuracy_cp2: 0.5301 - top_20_categorical_accuracy_cp3: 0.5965 - top_20_categorical_accuracy_cp4: 0.6394 - top_20_categorical_accuracy_p0: 0.3617 - top_20_categorical_accuracy_p1: 0.3576 - top_20_categorical_accuracy_p2: 0.3882 - top_20_categorical_accuracy_p3: 0.4449 - top_20_categorical_accuracy_p4: 0.5599 - val_loss: 0.0732 - val_categorical_accuracy: 0.3239 - val_top_5_categorical_accuracy: 0.4480 - val_top_10_categorical_accuracy: 0.5129 - val_top_20_categorical_accuracy: 0.5246 - val_top_5_categorical_accuracy_cp0: 0.3705 - val_top_5_categorical_accuracy_cp1: 0.4362 - val_top_5_categorical_accuracy_cp2: 0.4581 - val_top_5_categorical_accuracy_cp3: 0.5026 - val_top_5_categorical_accuracy_cp4: 0.5753 - val_top_5_categorical_accuracy_p0: 0.4167 - val_top_5_categorical_accuracy_p1: 0.3729 - val_top_5_categorical_accuracy_p2: 0.3122 - val_top_5_categorical_accuracy_p3: 0.3549 - val_top_5_categorical_accuracy_p4: 0.4792 - val_top_10_categorical_accuracy_cp0: 0.4283 - val_top_10_categorical_accuracy_cp1: 0.4959 - val_top_10_categorical_accuracy_cp2: 0.5123 - val_top_10_categorical_accuracy_cp3: 0.5918 - val_top_10_categorical_accuracy_cp4: 0.6309 - val_top_10_categorical_accuracy_p0: 0.5000 - val_top_10_categorical_accuracy_p1: 0.4068 - val_top_10_categorical_accuracy_p2: 0.3460 - val_top_10_categorical_accuracy_p3: 0.4177 - val_top_10_categorical_accuracy_p4: 0.5428 - val_top_20_categorical_accuracy_cp0: 0.4347 - val_top_20_categorical_accuracy_cp1: 0.5002 - val_top_20_categorical_accuracy_cp2: 0.5201 - val_top_20_categorical_accuracy_cp3: 0.6063 - val_top_20_categorical_accuracy_cp4: 0.6353 - val_top_20_categorical_accuracy_p0: 0.5000 - val_top_20_categorical_accuracy_p1: 0.4068 - val_top_20_categorical_accuracy_p2: 0.3502 - val_top_20_categorical_accuracy_p3: 0.4240 - val_top_20_categorical_accuracy_p4: 0.5503\n",
      "Epoch 6/10\n",
      "351/351 [==============================] - 6s 17ms/step - loss: 0.0757 - categorical_accuracy: 0.1716 - top_5_categorical_accuracy: 0.4329 - top_10_categorical_accuracy: 0.4989 - top_20_categorical_accuracy: 0.5285 - top_5_categorical_accuracy_cp0: 0.3876 - top_5_categorical_accuracy_cp1: 0.4346 - top_5_categorical_accuracy_cp2: 0.4580 - top_5_categorical_accuracy_cp3: 0.5012 - top_5_categorical_accuracy_cp4: 0.5566 - top_5_categorical_accuracy_p0: 0.2128 - top_5_categorical_accuracy_p1: 0.3015 - top_5_categorical_accuracy_p2: 0.3312 - top_5_categorical_accuracy_p3: 0.3806 - top_5_categorical_accuracy_p4: 0.4775 - top_10_categorical_accuracy_cp0: 0.4426 - top_10_categorical_accuracy_cp1: 0.4979 - top_10_categorical_accuracy_cp2: 0.5119 - top_10_categorical_accuracy_cp3: 0.5689 - top_10_categorical_accuracy_cp4: 0.6224 - top_10_categorical_accuracy_p0: 0.3404 - top_10_categorical_accuracy_p1: 0.3472 - top_10_categorical_accuracy_p2: 0.3749 - top_10_categorical_accuracy_p3: 0.4288 - top_10_categorical_accuracy_p4: 0.5400 - top_20_categorical_accuracy_cp0: 0.4624 - top_20_categorical_accuracy_cp1: 0.5151 - top_20_categorical_accuracy_cp2: 0.5299 - top_20_categorical_accuracy_cp3: 0.5965 - top_20_categorical_accuracy_cp4: 0.6394 - top_20_categorical_accuracy_p0: 0.3617 - top_20_categorical_accuracy_p1: 0.3638 - top_20_categorical_accuracy_p2: 0.3956 - top_20_categorical_accuracy_p3: 0.4468 - top_20_categorical_accuracy_p4: 0.5600 - val_loss: 0.0728 - val_categorical_accuracy: 0.3081 - val_top_5_categorical_accuracy: 0.4330 - val_top_10_categorical_accuracy: 0.5146 - val_top_20_categorical_accuracy: 0.5312 - val_top_5_categorical_accuracy_cp0: 0.3553 - val_top_5_categorical_accuracy_cp1: 0.4078 - val_top_5_categorical_accuracy_cp2: 0.4392 - val_top_5_categorical_accuracy_cp3: 0.4868 - val_top_5_categorical_accuracy_cp4: 0.5586 - val_top_5_categorical_accuracy_p0: 0.3056 - val_top_5_categorical_accuracy_p1: 0.3390 - val_top_5_categorical_accuracy_p2: 0.2954 - val_top_5_categorical_accuracy_p3: 0.3403 - val_top_5_categorical_accuracy_p4: 0.4600 - val_top_10_categorical_accuracy_cp0: 0.4304 - val_top_10_categorical_accuracy_cp1: 0.4956 - val_top_10_categorical_accuracy_cp2: 0.5140 - val_top_10_categorical_accuracy_cp3: 0.5931 - val_top_10_categorical_accuracy_cp4: 0.6306 - val_top_10_categorical_accuracy_p0: 0.5000 - val_top_10_categorical_accuracy_p1: 0.4237 - val_top_10_categorical_accuracy_p2: 0.3460 - val_top_10_categorical_accuracy_p3: 0.4213 - val_top_10_categorical_accuracy_p4: 0.5434 - val_top_20_categorical_accuracy_cp0: 0.4432 - val_top_20_categorical_accuracy_cp1: 0.5032 - val_top_20_categorical_accuracy_cp2: 0.5250 - val_top_20_categorical_accuracy_cp3: 0.6093 - val_top_20_categorical_accuracy_cp4: 0.6362 - val_top_20_categorical_accuracy_p0: 0.5000 - val_top_20_categorical_accuracy_p1: 0.4407 - val_top_20_categorical_accuracy_p2: 0.3544 - val_top_20_categorical_accuracy_p3: 0.4368 - val_top_20_categorical_accuracy_p4: 0.5536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "351/351 [==============================] - 6s 17ms/step - loss: 0.0753 - categorical_accuracy: 0.1747 - top_5_categorical_accuracy: 0.3988 - top_10_categorical_accuracy: 0.4986 - top_20_categorical_accuracy: 0.5286 - top_5_categorical_accuracy_cp0: 0.3397 - top_5_categorical_accuracy_cp1: 0.3876 - top_5_categorical_accuracy_cp2: 0.4113 - top_5_categorical_accuracy_cp3: 0.4687 - top_5_categorical_accuracy_cp4: 0.5086 - top_5_categorical_accuracy_p0: 0.2128 - top_5_categorical_accuracy_p1: 0.2516 - top_5_categorical_accuracy_p2: 0.2816 - top_5_categorical_accuracy_p3: 0.3255 - top_5_categorical_accuracy_p4: 0.4339 - top_10_categorical_accuracy_cp0: 0.4382 - top_10_categorical_accuracy_cp1: 0.4914 - top_10_categorical_accuracy_cp2: 0.5065 - top_10_categorical_accuracy_cp3: 0.5665 - top_10_categorical_accuracy_cp4: 0.6165 - top_10_categorical_accuracy_p0: 0.3617 - top_10_categorical_accuracy_p1: 0.3264 - top_10_categorical_accuracy_p2: 0.3695 - top_10_categorical_accuracy_p3: 0.4246 - top_10_categorical_accuracy_p4: 0.5351 - top_20_categorical_accuracy_cp0: 0.4609 - top_20_categorical_accuracy_cp1: 0.5133 - top_20_categorical_accuracy_cp2: 0.5266 - top_20_categorical_accuracy_cp3: 0.5944 - top_20_categorical_accuracy_cp4: 0.6375 - top_20_categorical_accuracy_p0: 0.3617 - top_20_categorical_accuracy_p1: 0.3472 - top_20_categorical_accuracy_p2: 0.3892 - top_20_categorical_accuracy_p3: 0.4471 - top_20_categorical_accuracy_p4: 0.5578 - val_loss: 0.0724 - val_categorical_accuracy: 0.2864 - val_top_5_categorical_accuracy: 0.4213 - val_top_10_categorical_accuracy: 0.5112 - val_top_20_categorical_accuracy: 0.5321 - val_top_5_categorical_accuracy_cp0: 0.3225 - val_top_5_categorical_accuracy_cp1: 0.3791 - val_top_5_categorical_accuracy_cp2: 0.4136 - val_top_5_categorical_accuracy_cp3: 0.4799 - val_top_5_categorical_accuracy_cp4: 0.5343 - val_top_5_categorical_accuracy_p0: 0.2778 - val_top_5_categorical_accuracy_p1: 0.3051 - val_top_5_categorical_accuracy_p2: 0.2743 - val_top_5_categorical_accuracy_p3: 0.3157 - val_top_5_categorical_accuracy_p4: 0.4362 - val_top_10_categorical_accuracy_cp0: 0.4328 - val_top_10_categorical_accuracy_cp1: 0.4932 - val_top_10_categorical_accuracy_cp2: 0.5084 - val_top_10_categorical_accuracy_cp3: 0.5836 - val_top_10_categorical_accuracy_cp4: 0.6244 - val_top_10_categorical_accuracy_p0: 0.5000 - val_top_10_categorical_accuracy_p1: 0.4407 - val_top_10_categorical_accuracy_p2: 0.3629 - val_top_10_categorical_accuracy_p3: 0.4277 - val_top_10_categorical_accuracy_p4: 0.5380 - val_top_20_categorical_accuracy_cp0: 0.4474 - val_top_20_categorical_accuracy_cp1: 0.5044 - val_top_20_categorical_accuracy_cp2: 0.5231 - val_top_20_categorical_accuracy_cp3: 0.6067 - val_top_20_categorical_accuracy_cp4: 0.6378 - val_top_20_categorical_accuracy_p0: 0.5000 - val_top_20_categorical_accuracy_p1: 0.4407 - val_top_20_categorical_accuracy_p2: 0.3882 - val_top_20_categorical_accuracy_p3: 0.4359 - val_top_20_categorical_accuracy_p4: 0.5538\n",
      "Epoch 8/10\n",
      "351/351 [==============================] - 6s 16ms/step - loss: 0.0750 - categorical_accuracy: 0.1802 - top_5_categorical_accuracy: 0.3884 - top_10_categorical_accuracy: 0.4885 - top_20_categorical_accuracy: 0.5284 - top_5_categorical_accuracy_cp0: 0.3264 - top_5_categorical_accuracy_cp1: 0.3689 - top_5_categorical_accuracy_cp2: 0.3954 - top_5_categorical_accuracy_cp3: 0.4625 - top_5_categorical_accuracy_cp4: 0.4934 - top_5_categorical_accuracy_p0: 0.2340 - top_5_categorical_accuracy_p1: 0.2349 - top_5_categorical_accuracy_p2: 0.2757 - top_5_categorical_accuracy_p3: 0.3107 - top_5_categorical_accuracy_p4: 0.4200 - top_10_categorical_accuracy_cp0: 0.4223 - top_10_categorical_accuracy_cp1: 0.4738 - top_10_categorical_accuracy_cp2: 0.4906 - top_10_categorical_accuracy_cp3: 0.5572 - top_10_categorical_accuracy_cp4: 0.6024 - top_10_categorical_accuracy_p0: 0.2979 - top_10_categorical_accuracy_p1: 0.3222 - top_10_categorical_accuracy_p2: 0.3563 - top_10_categorical_accuracy_p3: 0.4084 - top_10_categorical_accuracy_p4: 0.5206 - top_20_categorical_accuracy_cp0: 0.4602 - top_20_categorical_accuracy_cp1: 0.5090 - top_20_categorical_accuracy_cp2: 0.5241 - top_20_categorical_accuracy_cp3: 0.5908 - top_20_categorical_accuracy_cp4: 0.6325 - top_20_categorical_accuracy_p0: 0.3617 - top_20_categorical_accuracy_p1: 0.3597 - top_20_categorical_accuracy_p2: 0.4034 - top_20_categorical_accuracy_p3: 0.4458 - top_20_categorical_accuracy_p4: 0.5542 - val_loss: 0.0722 - val_categorical_accuracy: 0.2581 - val_top_5_categorical_accuracy: 0.4013 - val_top_10_categorical_accuracy: 0.5054 - val_top_20_categorical_accuracy: 0.5379 - val_top_5_categorical_accuracy_cp0: 0.3040 - val_top_5_categorical_accuracy_cp1: 0.3649 - val_top_5_categorical_accuracy_cp2: 0.3817 - val_top_5_categorical_accuracy_cp3: 0.4696 - val_top_5_categorical_accuracy_cp4: 0.5008 - val_top_5_categorical_accuracy_p0: 0.2778 - val_top_5_categorical_accuracy_p1: 0.2712 - val_top_5_categorical_accuracy_p2: 0.2700 - val_top_5_categorical_accuracy_p3: 0.3039 - val_top_5_categorical_accuracy_p4: 0.4135 - val_top_10_categorical_accuracy_cp0: 0.4188 - val_top_10_categorical_accuracy_cp1: 0.4814 - val_top_10_categorical_accuracy_cp2: 0.4971 - val_top_10_categorical_accuracy_cp3: 0.5736 - val_top_10_categorical_accuracy_cp4: 0.6160 - val_top_10_categorical_accuracy_p0: 0.5000 - val_top_10_categorical_accuracy_p1: 0.4407 - val_top_10_categorical_accuracy_p2: 0.3713 - val_top_10_categorical_accuracy_p3: 0.4067 - val_top_10_categorical_accuracy_p4: 0.5273 - val_top_20_categorical_accuracy_cp0: 0.4517 - val_top_20_categorical_accuracy_cp1: 0.5074 - val_top_20_categorical_accuracy_cp2: 0.5279 - val_top_20_categorical_accuracy_cp3: 0.6103 - val_top_20_categorical_accuracy_cp4: 0.6378 - val_top_20_categorical_accuracy_p0: 0.5000 - val_top_20_categorical_accuracy_p1: 0.4407 - val_top_20_categorical_accuracy_p2: 0.3966 - val_top_20_categorical_accuracy_p3: 0.4395 - val_top_20_categorical_accuracy_p4: 0.5568\n",
      "Epoch 9/10\n",
      "351/351 [==============================] - 6s 17ms/step - loss: 0.0749 - categorical_accuracy: 0.1828 - top_5_categorical_accuracy: 0.3834 - top_10_categorical_accuracy: 0.4834 - top_20_categorical_accuracy: 0.5306 - top_5_categorical_accuracy_cp0: 0.3185 - top_5_categorical_accuracy_cp1: 0.3615 - top_5_categorical_accuracy_cp2: 0.3851 - top_5_categorical_accuracy_cp3: 0.4548 - top_5_categorical_accuracy_cp4: 0.4859 - top_5_categorical_accuracy_p0: 0.1915 - top_5_categorical_accuracy_p1: 0.2328 - top_5_categorical_accuracy_p2: 0.2658 - top_5_categorical_accuracy_p3: 0.3060 - top_5_categorical_accuracy_p4: 0.4116 - top_10_categorical_accuracy_cp0: 0.4165 - top_10_categorical_accuracy_cp1: 0.4655 - top_10_categorical_accuracy_cp2: 0.4840 - top_10_categorical_accuracy_cp3: 0.5509 - top_10_categorical_accuracy_cp4: 0.5949 - top_10_categorical_accuracy_p0: 0.3404 - top_10_categorical_accuracy_p1: 0.3368 - top_10_categorical_accuracy_p2: 0.3572 - top_10_categorical_accuracy_p3: 0.4021 - top_10_categorical_accuracy_p4: 0.5134 - top_20_categorical_accuracy_cp0: 0.4603 - top_20_categorical_accuracy_cp1: 0.5082 - top_20_categorical_accuracy_cp2: 0.5250 - top_20_categorical_accuracy_cp3: 0.5912 - top_20_categorical_accuracy_cp4: 0.6321 - top_20_categorical_accuracy_p0: 0.3404 - top_20_categorical_accuracy_p1: 0.3472 - top_20_categorical_accuracy_p2: 0.4108 - top_20_categorical_accuracy_p3: 0.4464 - top_20_categorical_accuracy_p4: 0.5541 - val_loss: 0.0721 - val_categorical_accuracy: 0.2739 - val_top_5_categorical_accuracy: 0.4238 - val_top_10_categorical_accuracy: 0.4996 - val_top_20_categorical_accuracy: 0.5387 - val_top_5_categorical_accuracy_cp0: 0.3283 - val_top_5_categorical_accuracy_cp1: 0.3779 - val_top_5_categorical_accuracy_cp2: 0.4139 - val_top_5_categorical_accuracy_cp3: 0.4841 - val_top_5_categorical_accuracy_cp4: 0.5334 - val_top_5_categorical_accuracy_p0: 0.3056 - val_top_5_categorical_accuracy_p1: 0.2881 - val_top_5_categorical_accuracy_p2: 0.2996 - val_top_5_categorical_accuracy_p3: 0.3103 - val_top_5_categorical_accuracy_p4: 0.4380 - val_top_10_categorical_accuracy_cp0: 0.4149 - val_top_10_categorical_accuracy_cp1: 0.4685 - val_top_10_categorical_accuracy_cp2: 0.4903 - val_top_10_categorical_accuracy_cp3: 0.5700 - val_top_10_categorical_accuracy_cp4: 0.6111 - val_top_10_categorical_accuracy_p0: 0.4167 - val_top_10_categorical_accuracy_p1: 0.4407 - val_top_10_categorical_accuracy_p2: 0.3713 - val_top_10_categorical_accuracy_p3: 0.4022 - val_top_10_categorical_accuracy_p4: 0.5207 - val_top_20_categorical_accuracy_cp0: 0.4508 - val_top_20_categorical_accuracy_cp1: 0.5083 - val_top_20_categorical_accuracy_cp2: 0.5289 - val_top_20_categorical_accuracy_cp3: 0.6110 - val_top_20_categorical_accuracy_cp4: 0.6378 - val_top_20_categorical_accuracy_p0: 0.5000 - val_top_20_categorical_accuracy_p1: 0.4407 - val_top_20_categorical_accuracy_p2: 0.3924 - val_top_20_categorical_accuracy_p3: 0.4359 - val_top_20_categorical_accuracy_p4: 0.5575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "351/351 [==============================] - 6s 17ms/step - loss: 0.0747 - categorical_accuracy: 0.1789 - top_5_categorical_accuracy: 0.3797 - top_10_categorical_accuracy: 0.4817 - top_20_categorical_accuracy: 0.5301 - top_5_categorical_accuracy_cp0: 0.3169 - top_5_categorical_accuracy_cp1: 0.3604 - top_5_categorical_accuracy_cp2: 0.3881 - top_5_categorical_accuracy_cp3: 0.4490 - top_5_categorical_accuracy_cp4: 0.4810 - top_5_categorical_accuracy_p0: 0.1915 - top_5_categorical_accuracy_p1: 0.2266 - top_5_categorical_accuracy_p2: 0.2609 - top_5_categorical_accuracy_p3: 0.3044 - top_5_categorical_accuracy_p4: 0.4095 - top_10_categorical_accuracy_cp0: 0.4152 - top_10_categorical_accuracy_cp1: 0.4659 - top_10_categorical_accuracy_cp2: 0.4840 - top_10_categorical_accuracy_cp3: 0.5495 - top_10_categorical_accuracy_cp4: 0.5932 - top_10_categorical_accuracy_p0: 0.3191 - top_10_categorical_accuracy_p1: 0.3202 - top_10_categorical_accuracy_p2: 0.3582 - top_10_categorical_accuracy_p3: 0.4021 - top_10_categorical_accuracy_p4: 0.5126 - top_20_categorical_accuracy_cp0: 0.4605 - top_20_categorical_accuracy_cp1: 0.5076 - top_20_categorical_accuracy_cp2: 0.5229 - top_20_categorical_accuracy_cp3: 0.5902 - top_20_categorical_accuracy_cp4: 0.6306 - top_20_categorical_accuracy_p0: 0.3404 - top_20_categorical_accuracy_p1: 0.3576 - top_20_categorical_accuracy_p2: 0.4143 - top_20_categorical_accuracy_p3: 0.4494 - top_20_categorical_accuracy_p4: 0.5527 - val_loss: 0.0720 - val_categorical_accuracy: 0.2681 - val_top_5_categorical_accuracy: 0.4188 - val_top_10_categorical_accuracy: 0.4971 - val_top_20_categorical_accuracy: 0.5387 - val_top_5_categorical_accuracy_cp0: 0.3222 - val_top_5_categorical_accuracy_cp1: 0.3676 - val_top_5_categorical_accuracy_cp2: 0.4012 - val_top_5_categorical_accuracy_cp3: 0.4861 - val_top_5_categorical_accuracy_cp4: 0.5259 - val_top_5_categorical_accuracy_p0: 0.2778 - val_top_5_categorical_accuracy_p1: 0.2881 - val_top_5_categorical_accuracy_p2: 0.3080 - val_top_5_categorical_accuracy_p3: 0.3076 - val_top_5_categorical_accuracy_p4: 0.4304 - val_top_10_categorical_accuracy_cp0: 0.4131 - val_top_10_categorical_accuracy_cp1: 0.4645 - val_top_10_categorical_accuracy_cp2: 0.4896 - val_top_10_categorical_accuracy_cp3: 0.5674 - val_top_10_categorical_accuracy_cp4: 0.6089 - val_top_10_categorical_accuracy_p0: 0.3889 - val_top_10_categorical_accuracy_p1: 0.4407 - val_top_10_categorical_accuracy_p2: 0.3671 - val_top_10_categorical_accuracy_p3: 0.4013 - val_top_10_categorical_accuracy_p4: 0.5184 - val_top_20_categorical_accuracy_cp0: 0.4514 - val_top_20_categorical_accuracy_cp1: 0.5092 - val_top_20_categorical_accuracy_cp2: 0.5289 - val_top_20_categorical_accuracy_cp3: 0.6116 - val_top_20_categorical_accuracy_cp4: 0.6381 - val_top_20_categorical_accuracy_p0: 0.5000 - val_top_20_categorical_accuracy_p1: 0.4407 - val_top_20_categorical_accuracy_p2: 0.3924 - val_top_20_categorical_accuracy_p3: 0.4386 - val_top_20_categorical_accuracy_p4: 0.5578\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model.train_dataset(\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    experiment_config.multilabel_classification,\n",
    "    experiment_config.n_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "267f6291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging dataset info\n",
    "mlflow.log_metric(\"train_size\", len([x for x in train_dataset]))\n",
    "mlflow.log_metric(\"test_size\", len([x for x in test_dataset]))\n",
    "mlflow.log_metric(\"x_vocab_size\", len(metadata.x_vocab))\n",
    "mlflow.log_metric(\"y_vocab_size\", len(metadata.y_vocab))\n",
    "\n",
    "# generate artifacts\n",
    "# skip\n",
    "\n",
    "# set mlflow tags\n",
    "mlflow.set_tag(\"sequence_type\", experiment_config.sequence_type)\n",
    "mlflow.set_tag(\"model_type\", experiment_config.model_type)\n",
    "if len(metadata.y_vocab) == 1:\n",
    "    mlflow.set_tag(\"task_type\", \"risk_prediction\")\n",
    "else:\n",
    "    mlflow.set_tag(\"task_type\", \"sequence_prediction\")\n",
    "\n",
    "logging.info(\"Finished run %s\", run_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21272d77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
